{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe vectors (Tilo)\n",
    "\n",
    "I used [this](https://jsomers.net/glove-codenames/) blogpost as a guide. It's a fun and easy read about using GloVe vectors to play the popular boadgame Codenames so if that sounds intresting check it out. I use some code snippets from this blogpost.\n",
    " \n",
    "I downloaded my GloVe vectors from http://nlp.stanford.edu/data/glove.42B.300d.zip. This file has vectors for more than a million words, so I just used the vectors from the top 100,000 words.\n",
    "\n",
    "If you want to skip to see the recommender in action [click this link](#Testing-out-the-recommender). It seems to work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "#df =pd.read_csv(\"courses_raw.csv\", error_bad_lines=False)\n",
    "df = pd.read_json(\"data_5scheduler.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {}\n",
    "with open(\"./top_100000.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings[word] = vector\n",
    "        \n",
    "words_with_embeddings = set([w for w in embeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def calculate_description_embeding(description):\n",
    "    \n",
    "    # clean description\n",
    "    description = remove_punctuation(description).lower().strip()\n",
    "    words = description.split(\" \")\n",
    "    stops = set(stopwords.words('english'))\n",
    "    \n",
    "    # filter out stop words and words we don't have embeddings for\n",
    "    words = [w for w in words if not w in stops]\n",
    "    words = [w for w in words if (w in words_with_embeddings)]\n",
    "    \n",
    "    if len(words) == 0:\n",
    "        return None\n",
    "    \n",
    "    # calculate embedding and return\n",
    "    return sum([embeddings[w] for w in words])/len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description embeddings\"] = [calculate_description_embeding(desc) for desc in df[\"description\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_embeddings = df[[\"title\",\"description embeddings\"]].set_index(\"title\").dropna().to_dict()['description embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3687"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(description_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(title):\n",
    "    '''Finds 10 closest courses for a given course by taking the cosine similarity of their description embeddings.'''\n",
    "    \n",
    "    def distance(title, reference):\n",
    "        return spatial.distance.cosine(description_embeddings[title], description_embeddings[reference])\n",
    "\n",
    "    def closest_courses(reference):\n",
    "        return sorted(description_embeddings.keys(), key=lambda w: distance(w, reference))\n",
    "    \n",
    "    return closest_courses(title)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing out the recommender\n",
    "Here I test the recommender on some classes I've taken or am taking. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Linear Algebra',\n",
       " 'Linear Algebra with Computing',\n",
       " 'Mathematical Methods of Physics',\n",
       " 'Precalculus',\n",
       " 'Calculus with Precalculus',\n",
       " 'Mathematical Analysis II',\n",
       " 'Engineering Mathematics',\n",
       " 'Single and Multivariable Calculus',\n",
       " 'Fourier Series and Boundary Value Problems',\n",
       " 'Scientific Computing']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend('Linear Algebra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Language and Gender',\n",
       " 'Language and Globalization',\n",
       " 'Morphosyntax',\n",
       " 'The Socialization of Gender: A Developmental Perspective',\n",
       " 'Language and Society',\n",
       " 'Language in Society',\n",
       " 'Chinese Language in Society',\n",
       " 'Language, Identity and Violence',\n",
       " 'Language and Power',\n",
       " 'Introduction to the Study of Language']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend('Language and Gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though Econometrics is in the econ deparment it's really a stats class and it seems like the recommender is aware of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Econometrics',\n",
       " 'Statistical Inference',\n",
       " 'Applied Statistics',\n",
       " 'Bayesian Statistics',\n",
       " 'Calculus and Discrete Models for Applications',\n",
       " 'Methods in Modern Modeling',\n",
       " 'Representations of High-Dimensional Data',\n",
       " 'Time Series',\n",
       " 'Computational Statistics',\n",
       " 'Differential Equations and Modeling']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend('Econometrics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some stuff I'd like to fix about the recommender\n",
    "I think it seems to be working pretty well. However, here's a list of stuff I'd like to fix about the recommender:\n",
    "- Handle classes that have the same name but are different; currently if two classes have the same name only one of their descriptions is being used. (Or at least I think that's what's going on with duplicate course names).\n",
    "- Handle hyphonated words better; when I calculate description embeddings I get rid of all punctuation (e.g. \"single-gender\" becomes \"singlegender\"). \n",
    "- Investigate why some words don't have embeddings. For example, \"singlegender\" doesn't have an embedding but that's something that could potentially be fixed if it was treated as two words or the hyphen was not removed. \n",
    "\n",
    "# Go test it out youself!\n",
    "\n",
    "\n",
    "To get the code running you'll need a file called \"top_100000.txt\" with the top 100,000 GloVe vectors. You can get the GloVe vectors from http://nlp.stanford.edu/data/glove.42B.300d.zip. Be warned though, the unzipped file is 5 MB. After you've got the unzipped file, run this in your terminal to get the \"top_100000.txt\" file.\n",
    "```\n",
    "head -n 100000 glove.42B.300d.txt > top_100000.txt\n",
    "```\n",
    "Feel free to play around with with the recomender. If you run the cell bellow it will give you a list of all the courses that have embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[desc for desc in description_embeddings]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
