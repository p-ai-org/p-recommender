{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title   identifier  \\\n",
      "0                  Introduction to American Cultures  AMST-103-HM   \n",
      "1                         Print and American Culture  AMST-115-HM   \n",
      "2                               Hyphenated Americans  AMST-120-HM   \n",
      "3    Life: Knowledge, Belief, and Cultural Practices  ANTH-110-HM   \n",
      "4  Introduction to the Anthropology of Science an...  ANTH-111-HM   \n",
      "\n",
      "                                         description      source  credits  \\\n",
      "0  An interdisciplinary introduction to principal...  HarveyMudd      300   \n",
      "1  Covers numerous developments in American print...  HarveyMudd      300   \n",
      "2  A focus on the experience of immigrants in the...  HarveyMudd      300   \n",
      "3  An exploration of cultural attitudes toward li...  HarveyMudd      300   \n",
      "4  An introduction to science and technology as c...  HarveyMudd      300   \n",
      "\n",
      "          instructors offered prerequisites corequisites  currently_offered  \\\n",
      "0             [Staff]                                                 False   \n",
      "1        [Anup Gampa]                                                  True   \n",
      "2          [Balseiro]                                                 False   \n",
      "3           [de Laet]                                                 False   \n",
      "4  [Marianne De Laet]                                                  True   \n",
      "\n",
      "   fee  \n",
      "0    0  \n",
      "1    0  \n",
      "2    0  \n",
      "3    0  \n",
      "4    0  \n",
      "harvey mudd courses 377\n",
      "pomona courses 1446\n",
      "claremont courses 816\n",
      "scripps courses 943\n",
      "pitzer courses 861\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "file = r\"/Users/yotamtwersky/Documents/GitHub/p-recommender/data-science/data_5scheduler.json\"\n",
    "error_lines_bad = False\n",
    "df = pd.read_json(file)\n",
    "print (df.head())\n",
    "\n",
    "\n",
    "print(\"harvey mudd courses \" + str(len(df[df.source == \"HarveyMudd\"])))\n",
    "print(\"pomona courses \" + str(len(df[df.source == \"Pomona\"])))\n",
    "print(\"claremont courses \" + str(len(df[df.source == \"ClaremontMckenna\"])))\n",
    "print(\"scripps courses \" + str(len(df[df.source == \"Scripps\"])))\n",
    "print(\"pitzer courses \" + str(len(df[df.source == \"Pitzer\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfTransformer \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer \n\u001b[1;32m      5\u001b[0m docs\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe house had a tiny little mouse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe cat saw the mouse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe mouse ran away from the house\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      8\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe cat finally ate the mouse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe end of the mouse story\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m ]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "docs=[\"the house had a tiny little mouse\", \n",
    "\"the cat saw the mouse\", \n",
    "\"the mouse ran away from the house\", \n",
    "\"the cat finally ate the mouse\", \n",
    "\"the end of the mouse story\"\n",
    "]\n",
    "#instantiate CountVectorizer() \n",
    "cv=CountVectorizer() \n",
    "# this steps generates word counts for the words in your docs \n",
    "word_count_vector=cv.fit_transform(docs)\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True) \n",
    "tfidf_transformer.fit(word_count_vector)\n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(),columns=[\"idf_weights\"]) \n",
    "# sort ascending \n",
    "df_idf.sort_values(by=['idf_weights'])\n",
    "# count matrix \n",
    "count_vector=cv.transform(docs) \n",
    "# tf-idf scores \n",
    "tf_idf_vector=tfidf_transformer.transform(count_vector)\n",
    "\n",
    "feature_names = cv.get_feature_names() \n",
    "#get tfidf vector for first document \n",
    "first_document_vector=tf_idf_vector[0] \n",
    "#print the scores \n",
    "df = pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"]) \n",
    "df.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
