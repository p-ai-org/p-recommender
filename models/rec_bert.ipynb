{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: transformers<5.0.0,>=4.6.0 in /opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers) (4.18.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers) (4.47.0)\n",
      "Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: torchvision in /opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers) (0.13.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers) (1.22.3)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers) (1.8.0)\n",
      "Requirement already satisfied, skipping upgrade: nltk in /opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers) (3.5)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp38-cp38-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 11.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: huggingface-hub>=0.4.0 in /opt/anaconda3/lib/python3.8/site-packages (from sentence-transformers) (0.5.1)\n",
      "Requirement already satisfied, skipping upgrade: filelock in /opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied, skipping upgrade: sacremoses in /opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.51)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (20.4)\n",
      "Requirement already satisfied, skipping upgrade: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml>=5.1 in /opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /opt/anaconda3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2020.6.8)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions in /opt/anaconda3/lib/python3.8/site-packages (from torch>=1.6.0->sentence-transformers) (4.0.1)\n",
      "Requirement already satisfied, skipping upgrade: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.8/site-packages (from torchvision->sentence-transformers) (7.2.0)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sentence-transformers) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: click in /opt/anaconda3/lib/python3.8/site-packages (from nltk->sentence-transformers) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.25.9)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125919 sha256=955cb86338db923ee144dc9b3b0c86b7aa981babb373ea5c13760789bc5435d3\n",
      "  Stored in directory: /Users/vanisachdev/Library/Caches/pip/wheels/5e/6f/8c/d88aec621f3f542d26fac0342bef5e693335d125f4e54aeffe\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentencepiece, sentence-transformers\n",
      "Successfully installed sentence-transformers-2.2.2 sentencepiece-0.1.97\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"/Users/vanisachdev/Desktop/github/p-recommender/data_science/cleaned_data5scheduler.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>identifier</th>\n",
       "      <th>description</th>\n",
       "      <th>source</th>\n",
       "      <th>credits</th>\n",
       "      <th>instructors</th>\n",
       "      <th>offered</th>\n",
       "      <th>prerequisites</th>\n",
       "      <th>corequisites</th>\n",
       "      <th>currently_offered</th>\n",
       "      <th>fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Introduction to American Cultures</td>\n",
       "      <td>AMST-103-HM</td>\n",
       "      <td>An interdisciplinary introduction to principal...</td>\n",
       "      <td>HarveyMudd</td>\n",
       "      <td>100</td>\n",
       "      <td>[Staff]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Print and American Culture</td>\n",
       "      <td>AMST-115-HM</td>\n",
       "      <td>Covers numerous developments in American print...</td>\n",
       "      <td>HarveyMudd</td>\n",
       "      <td>100</td>\n",
       "      <td>[Anup Gampa]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hyphenated Americans</td>\n",
       "      <td>AMST-120-HM</td>\n",
       "      <td>A focus on the experience of immigrants in the...</td>\n",
       "      <td>HarveyMudd</td>\n",
       "      <td>100</td>\n",
       "      <td>[Balseiro]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Life: Knowledge, Belief, and Cultural Practices</td>\n",
       "      <td>ANTH-110-HM</td>\n",
       "      <td>An exploration of cultural attitudes toward li...</td>\n",
       "      <td>HarveyMudd</td>\n",
       "      <td>100</td>\n",
       "      <td>[de Laet]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Introduction to the Anthropology of Science an...</td>\n",
       "      <td>ANTH-111-HM</td>\n",
       "      <td>An introduction to science and technology as c...</td>\n",
       "      <td>HarveyMudd</td>\n",
       "      <td>100</td>\n",
       "      <td>[Marianne De Laet]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   identifier  \\\n",
       "0                  Introduction to American Cultures  AMST-103-HM   \n",
       "1                         Print and American Culture  AMST-115-HM   \n",
       "2                               Hyphenated Americans  AMST-120-HM   \n",
       "3    Life: Knowledge, Belief, and Cultural Practices  ANTH-110-HM   \n",
       "4  Introduction to the Anthropology of Science an...  ANTH-111-HM   \n",
       "\n",
       "                                         description      source  credits  \\\n",
       "0  An interdisciplinary introduction to principal...  HarveyMudd      100   \n",
       "1  Covers numerous developments in American print...  HarveyMudd      100   \n",
       "2  A focus on the experience of immigrants in the...  HarveyMudd      100   \n",
       "3  An exploration of cultural attitudes toward li...  HarveyMudd      100   \n",
       "4  An introduction to science and technology as c...  HarveyMudd      100   \n",
       "\n",
       "          instructors offered prerequisites corequisites  currently_offered  \\\n",
       "0             [Staff]                                                 False   \n",
       "1        [Anup Gampa]                                                  True   \n",
       "2          [Balseiro]                                                 False   \n",
       "3           [de Laet]                                                 False   \n",
       "4  [Marianne De Laet]                                                  True   \n",
       "\n",
       "   fee  \n",
       "0    0  \n",
       "1    0  \n",
       "2    0  \n",
       "3    0  \n",
       "4    0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lens = [len(x.split()) for x in df['description']]\n",
    "\n",
    "plt.hist(lens, bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/vanisachdev/.cache/torch/sentence_transformers/bert-base-uncased. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /Users/vanisachdev/.cache/torch/sentence_transformers/bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Import library, utilities \n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# Set embedding model and max_seq_len and push to GPU\n",
    "embedder = SentenceTransformer('bert-base-uncased')\n",
    "# embedder.to('cuda')\n",
    "# going a little longer for user inputed synopsis\n",
    "embedder.max_seq_len = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df['title'].tolist()\n",
    "description = df['description'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/vanisachdev/Desktop/github/p-recommender/models/rec_bert.ipynb Cell 7\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vanisachdev/Desktop/github/p-recommender/models/rec_bert.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m story_embeddings \u001b[39m=\u001b[39m embedder\u001b[39m.\u001b[39;49mencode(description, convert_to_tensor\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sentence_transformers/SentenceTransformer.py:165\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    162\u001b[0m features \u001b[39m=\u001b[39m batch_to_device(features, device)\n\u001b[1;32m    164\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 165\u001b[0m     out_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(features)\n\u001b[1;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m output_value \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    168\u001b[0m         embeddings \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sentence_transformers/models/Transformer.py:66\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m features:\n\u001b[1;32m     64\u001b[0m     trans_features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 66\u001b[0m output_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauto_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrans_features, return_dict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     67\u001b[0m output_tokens \u001b[39m=\u001b[39m output_states[\u001b[39m0\u001b[39m]\n\u001b[1;32m     69\u001b[0m features\u001b[39m.\u001b[39mupdate({\u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m: output_tokens, \u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m: features[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]})\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:996\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    987\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    989\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    990\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m    991\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    994\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    995\u001b[0m )\n\u001b[0;32m--> 996\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    997\u001b[0m     embedding_output,\n\u001b[1;32m    998\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    999\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1000\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1001\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1002\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1003\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1004\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1005\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1006\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1007\u001b[0m )\n\u001b[1;32m   1008\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1009\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    576\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    577\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    578\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    583\u001b[0m     )\n\u001b[1;32m    584\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 585\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    586\u001b[0m         hidden_states,\n\u001b[1;32m    587\u001b[0m         attention_mask,\n\u001b[1;32m    588\u001b[0m         layer_head_mask,\n\u001b[1;32m    589\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    590\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    591\u001b[0m         past_key_value,\n\u001b[1;32m    592\u001b[0m         output_attentions,\n\u001b[1;32m    593\u001b[0m     )\n\u001b[1;32m    595\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    596\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:513\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    510\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    511\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 513\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[1;32m    514\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[1;32m    515\u001b[0m )\n\u001b[1;32m    516\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[1;32m    518\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/transformers/modeling_utils.py:2928\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2925\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m   2926\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[0;32m-> 2928\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:525\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[0;32m--> 525\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate(attention_output)\n\u001b[1;32m    526\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    527\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:426\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m--> 426\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[1;32m    427\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    428\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "story_embeddings = embedder.encode(description, convert_to_tensor=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
